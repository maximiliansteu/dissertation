{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62623bde87a444e987279486f1aa42a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1d2a70d3bcf4f768bdb55208d142368",
              "IPY_MODEL_27e53acd70584abab4481469e0d3c87e",
              "IPY_MODEL_fe00ac006fe243c18ee60cfeabccabea"
            ],
            "layout": "IPY_MODEL_f7bd61876cb44f86b313245d0fa7dd5e"
          }
        },
        "e1d2a70d3bcf4f768bdb55208d142368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f989db61681647de955cbd82d8697531",
            "placeholder": "​",
            "style": "IPY_MODEL_b763985558624c4a8ecf892e866e66f2",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "27e53acd70584abab4481469e0d3c87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa7551428e549229d99a51f9c50cf3e",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4886b6096d2f439cab4dd0c6eb6029da",
            "value": 666
          }
        },
        "fe00ac006fe243c18ee60cfeabccabea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69381aef9674192934ab5a68879ea9d",
            "placeholder": "​",
            "style": "IPY_MODEL_80b98ff6cc964d22a24414245c1c0706",
            "value": " 666/666 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "f7bd61876cb44f86b313245d0fa7dd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f989db61681647de955cbd82d8697531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b763985558624c4a8ecf892e866e66f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfa7551428e549229d99a51f9c50cf3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4886b6096d2f439cab4dd0c6eb6029da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d69381aef9674192934ab5a68879ea9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b98ff6cc964d22a24414245c1c0706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbb0db3870564407a12a594cb7e87839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_002744d6f3b34be6b4bdc17dd172a74f",
              "IPY_MODEL_95baed6cdf204dcaa3111af5e0ce7c33",
              "IPY_MODEL_2e258c82fcf1409588c791ba4ce6c80d"
            ],
            "layout": "IPY_MODEL_493eb89b793b4a3ab52a3e57ac48e95b"
          }
        },
        "002744d6f3b34be6b4bdc17dd172a74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de562d50f364f899a8b5f4f737409a6",
            "placeholder": "​",
            "style": "IPY_MODEL_2ac2d5b74da34b6c914531a3e8a0e7d9",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "95baed6cdf204dcaa3111af5e0ce7c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51a60a47fb7a4a47acead5087237d1ad",
            "max": 440343552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33319ede618e4c2698e7828a025e2b41",
            "value": 440343552
          }
        },
        "2e258c82fcf1409588c791ba4ce6c80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34d0c88b802441e8a079dc3140738abc",
            "placeholder": "​",
            "style": "IPY_MODEL_266b0c31b7514463a364d31076e27802",
            "value": " 440M/440M [00:01&lt;00:00, 262MB/s]"
          }
        },
        "493eb89b793b4a3ab52a3e57ac48e95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de562d50f364f899a8b5f4f737409a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac2d5b74da34b6c914531a3e8a0e7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a60a47fb7a4a47acead5087237d1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33319ede618e4c2698e7828a025e2b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34d0c88b802441e8a079dc3140738abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266b0c31b7514463a364d31076e27802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a82d371b33d445afb1ef37792c75d676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd45d0035b1647449b8a272b3d4237ac",
              "IPY_MODEL_1caed4b35555492ca1a4b9ac3d4eb69d",
              "IPY_MODEL_be1926f35a934b758fce3162e5d91e25"
            ],
            "layout": "IPY_MODEL_7dd1739dff5a49cda29c4a69924ac0f5"
          }
        },
        "dd45d0035b1647449b8a272b3d4237ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46174b0b06b24c06ac3e5df334d110a2",
            "placeholder": "​",
            "style": "IPY_MODEL_836fd738b70944988b5a93f025afd914",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1caed4b35555492ca1a4b9ac3d4eb69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875946d7b2bb438bb1fcb5df5fca4ad3",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91c94de663e7462bae017b2325881201",
            "value": 27
          }
        },
        "be1926f35a934b758fce3162e5d91e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0347ce3292c24ff897793ff66a564893",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8a300238b04c42be42376981d33eac",
            "value": " 27.0/27.0 [00:00&lt;00:00, 1.96kB/s]"
          }
        },
        "7dd1739dff5a49cda29c4a69924ac0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46174b0b06b24c06ac3e5df334d110a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836fd738b70944988b5a93f025afd914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "875946d7b2bb438bb1fcb5df5fca4ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c94de663e7462bae017b2325881201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0347ce3292c24ff897793ff66a564893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8a300238b04c42be42376981d33eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3442f384b3cf493a9c57d76006da6242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aebb25915cae48458076cd3a22fb62d0",
              "IPY_MODEL_2ae0260f40404fbd87a388b5d5b86739",
              "IPY_MODEL_0ccd0f781689451f8bb861c37f67d8d1"
            ],
            "layout": "IPY_MODEL_789bcb8d79e64ea49ed0876ede4bcc5a"
          }
        },
        "aebb25915cae48458076cd3a22fb62d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba5e4353c504f2bafe8b496bc2d83bd",
            "placeholder": "​",
            "style": "IPY_MODEL_cae5643d0a9a444a91fbc8c7804ab375",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "2ae0260f40404fbd87a388b5d5b86739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e0602407c24c07937d897a47d27322",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61717f49688f4b1a8caf99ca12d83bac",
            "value": 231508
          }
        },
        "0ccd0f781689451f8bb861c37f67d8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be26252481534baf949d321dc5955767",
            "placeholder": "​",
            "style": "IPY_MODEL_9c1ea0dd18d645abbbe86b7add71d3d8",
            "value": " 232k/232k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "789bcb8d79e64ea49ed0876ede4bcc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba5e4353c504f2bafe8b496bc2d83bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae5643d0a9a444a91fbc8c7804ab375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e0602407c24c07937d897a47d27322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61717f49688f4b1a8caf99ca12d83bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be26252481534baf949d321dc5955767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1ea0dd18d645abbbe86b7add71d3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e46deb86394e6b8bd910a1260ffb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5009481405f443aba7142a25125ed381",
              "IPY_MODEL_a1bab205b93743d68842e441a649d718",
              "IPY_MODEL_84414f141c1c4f88bdb207c0f9fbe8f8"
            ],
            "layout": "IPY_MODEL_bb8f4c482498466494082d4cfaac7e23"
          }
        },
        "5009481405f443aba7142a25125ed381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d166ce41aea54429b8aa9a149b6cab0d",
            "placeholder": "​",
            "style": "IPY_MODEL_ec907684a7f94a07afde6019dd062ec3",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "a1bab205b93743d68842e441a649d718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b2d2932a9b437e99224b79a256eb77",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b801b9f38f3b43a88854ae2457380007",
            "value": 466062
          }
        },
        "84414f141c1c4f88bdb207c0f9fbe8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a8e8e898b74315b40cc76c36baf384",
            "placeholder": "​",
            "style": "IPY_MODEL_b00da1b6de1245f297ef8f20273d75c8",
            "value": " 466k/466k [00:00&lt;00:00, 1.89MB/s]"
          }
        },
        "bb8f4c482498466494082d4cfaac7e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d166ce41aea54429b8aa9a149b6cab0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec907684a7f94a07afde6019dd062ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55b2d2932a9b437e99224b79a256eb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b801b9f38f3b43a88854ae2457380007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0a8e8e898b74315b40cc76c36baf384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00da1b6de1245f297ef8f20273d75c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d190a45d208429a92970246363052e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85fcbab795b54120a25daf6e1685fb9f",
              "IPY_MODEL_3ebb070c088a422dbef02924c513d2f7",
              "IPY_MODEL_39b0ab7c0d70486dbf221c25ac5252fb"
            ],
            "layout": "IPY_MODEL_3f0897d9da88455da624a35dcbfad6ad"
          }
        },
        "85fcbab795b54120a25daf6e1685fb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7db675ace1a434ea589eab66eaab57c",
            "placeholder": "​",
            "style": "IPY_MODEL_21e4aa8d63a046469bdea1b4e0ab6efa",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "3ebb070c088a422dbef02924c513d2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561075b73fc24571a14c9098f88a06a7",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2035337872c74fbca8be4ab5d00be7e9",
            "value": 666
          }
        },
        "39b0ab7c0d70486dbf221c25ac5252fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f6cdee08024119889cf2416115757c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed39ce37dd2e4ed6974fe0304c7434e5",
            "value": " 666/666 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "3f0897d9da88455da624a35dcbfad6ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7db675ace1a434ea589eab66eaab57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e4aa8d63a046469bdea1b4e0ab6efa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "561075b73fc24571a14c9098f88a06a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2035337872c74fbca8be4ab5d00be7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20f6cdee08024119889cf2416115757c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed39ce37dd2e4ed6974fe0304c7434e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab190718ccb04fc78957b76173a6d0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef03b473768e4c9c88e3dbf5f53cb4c9",
              "IPY_MODEL_be89323e859f480d93fed13bcb20bbee",
              "IPY_MODEL_3faa62924f5746ebb529e3797d5acc7b"
            ],
            "layout": "IPY_MODEL_3b2716c53be84aab9d464b3a55d65b6a"
          }
        },
        "ef03b473768e4c9c88e3dbf5f53cb4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b36d47f5f42417a88321303f6e49b5b",
            "placeholder": "​",
            "style": "IPY_MODEL_a43d217ff49146e88e323a89e72ff921",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "be89323e859f480d93fed13bcb20bbee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d1574fd2b424f4cb1f0aabe8fecead6",
            "max": 440343552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72d43a2e117d481ba45cb0809af08b29",
            "value": 440343552
          }
        },
        "3faa62924f5746ebb529e3797d5acc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd74ef002be4183898fa0fb957ac3a8",
            "placeholder": "​",
            "style": "IPY_MODEL_a66734a314984dbf9fd1cd100562b48d",
            "value": " 440M/440M [00:02&lt;00:00, 203MB/s]"
          }
        },
        "3b2716c53be84aab9d464b3a55d65b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b36d47f5f42417a88321303f6e49b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43d217ff49146e88e323a89e72ff921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1574fd2b424f4cb1f0aabe8fecead6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d43a2e117d481ba45cb0809af08b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcd74ef002be4183898fa0fb957ac3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66734a314984dbf9fd1cd100562b48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a088f99d19d4b778c362fba71ee2792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_826363421cf948afbebaf3e92d1ef5e8",
              "IPY_MODEL_d5333e3387ce418f85139e39c323ce7d",
              "IPY_MODEL_ce5675fca097438386a001d7d2935722"
            ],
            "layout": "IPY_MODEL_59fe610e2738442f805e87652963f8cc"
          }
        },
        "826363421cf948afbebaf3e92d1ef5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b167db6b112a4563982143be9281fb98",
            "placeholder": "​",
            "style": "IPY_MODEL_f33c25978bdc4399979268feaf30056e",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "d5333e3387ce418f85139e39c323ce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee9a41d272bb41a79c548cae712b3a9e",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64c4b7c823214919bfd3303e1b1f6cc4",
            "value": 27
          }
        },
        "ce5675fca097438386a001d7d2935722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57897f43c25c45108c3590f2cc4480a2",
            "placeholder": "​",
            "style": "IPY_MODEL_a98941799c704d47ad94f4b614a726ed",
            "value": " 27.0/27.0 [00:00&lt;00:00, 1.70kB/s]"
          }
        },
        "59fe610e2738442f805e87652963f8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b167db6b112a4563982143be9281fb98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33c25978bdc4399979268feaf30056e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9a41d272bb41a79c548cae712b3a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c4b7c823214919bfd3303e1b1f6cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57897f43c25c45108c3590f2cc4480a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98941799c704d47ad94f4b614a726ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eadfd8fb22a421f87b974788f4c0a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2505f9f4f8a4b7da4efda2206adca6e",
              "IPY_MODEL_4eeb90cd172c4537879b1061728559e0",
              "IPY_MODEL_0655ba02ee2540a183aaeac7cb6f8d03"
            ],
            "layout": "IPY_MODEL_431061fdce1544c8b7b0a704b261f9e8"
          }
        },
        "f2505f9f4f8a4b7da4efda2206adca6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186e07a2e0974bd3bfb837c7b2f80549",
            "placeholder": "​",
            "style": "IPY_MODEL_dedbb0e1e0c9447cbab3cb9138108df0",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "4eeb90cd172c4537879b1061728559e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97857558a3f54ec495f92ec4f85da021",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62ba1fe81d0d46e4bced07cf99d31c30",
            "value": 231508
          }
        },
        "0655ba02ee2540a183aaeac7cb6f8d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1d746951a74102b8991f84b75d7920",
            "placeholder": "​",
            "style": "IPY_MODEL_bc74391c9a414e45ac863bf731caa508",
            "value": " 232k/232k [00:00&lt;00:00, 4.08MB/s]"
          }
        },
        "431061fdce1544c8b7b0a704b261f9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186e07a2e0974bd3bfb837c7b2f80549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedbb0e1e0c9447cbab3cb9138108df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97857558a3f54ec495f92ec4f85da021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ba1fe81d0d46e4bced07cf99d31c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce1d746951a74102b8991f84b75d7920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc74391c9a414e45ac863bf731caa508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7218115f00eb4d008cb7c778770e8fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e11c0a711f664396ae28e3f5de046d4c",
              "IPY_MODEL_237bfba15d63476684deaeb64572f748",
              "IPY_MODEL_6bb366f99d634586bed3a7eba13108dd"
            ],
            "layout": "IPY_MODEL_66841b67e3834755bbce2dcfdbd40c67"
          }
        },
        "e11c0a711f664396ae28e3f5de046d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8621d6fc87044620932e9bdb631c6ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_ebcb9994d6f04a2c9e83b937dfb37974",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "237bfba15d63476684deaeb64572f748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b364de122514d0db881a2cb3e3711d2",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6b62229e6b74d9cb644febdedaf291f",
            "value": 466062
          }
        },
        "6bb366f99d634586bed3a7eba13108dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45de131671f74ab78a201feba748a61d",
            "placeholder": "​",
            "style": "IPY_MODEL_bf86384c00bc4223bb7d0788d1889fe7",
            "value": " 466k/466k [00:00&lt;00:00, 24.3MB/s]"
          }
        },
        "66841b67e3834755bbce2dcfdbd40c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8621d6fc87044620932e9bdb631c6ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebcb9994d6f04a2c9e83b937dfb37974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b364de122514d0db881a2cb3e3711d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b62229e6b74d9cb644febdedaf291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45de131671f74ab78a201feba748a61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf86384c00bc4223bb7d0788d1889fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED_TQLR3uB-6",
        "outputId": "ee869b8e-d7ff-4a6a-f089-2e796a207741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular[all]\n",
            "  Downloading autogluon.tabular-0.8.2-py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.10.1)\n",
            "Requirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.2.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (3.1)\n",
            "Collecting autogluon.core==0.8.2 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.core-0.8.2-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.8.2 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.features-0.8.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm<3.4,>=3.3 (from autogluon.tabular[all])\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.7.6)\n",
            "Collecting torch<1.14,>=1.9 (from autogluon.tabular[all])\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.7.12)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all])\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==0.8.2->autogluon.tabular[all]) (4.66.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==0.8.2->autogluon.tabular[all]) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==0.8.2->autogluon.tabular[all]) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading boto3-1.28.26-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==0.8.2 (from autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading autogluon.common-0.8.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==0.8.2->autogluon.tabular[all]) (0.2.7)\n",
            "Collecting ray[default]<2.4,>=2.3 (from autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading ray-2.3.1-cp310-cp310-manylinux2014_x86_64.whl (58.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0,>=1.10.4 (from autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<=1.50.0,>=1.42.0 (from autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading grpcio-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core==0.8.2->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core==0.8.2->autogluon.tabular[all]) (67.7.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (0.20.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]) (1.16.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (23.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.5.29)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (9.4.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.tabular[all]) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.tabular[all]) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.tabular[all]) (4.7.1)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<1.14,>=1.9->autogluon.tabular[all])\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<1.14,>=1.9->autogluon.tabular[all])\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.32.0,>=1.31.26 (from boto3<2,>=1.10->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading botocore-1.31.26-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2,>=1.10->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core==0.8.2->autogluon.tabular[all]) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core==0.8.2->autogluon.tabular[all]) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core==0.8.2->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (8.1.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (3.12.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (4.19.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (1.4.0)\n",
            "Collecting virtualenv>=20.0.24 (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading virtualenv-20.24.3-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (3.8.5)\n",
            "Collecting aiohttp-cors (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0 (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0 (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.17.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (6.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.9.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading tensorboardX-2.6.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (8.1.11)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==0.8.2->autogluon.tabular[all]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==0.8.2->autogluon.tabular[all]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==0.8.2->autogluon.tabular[all]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==0.8.2->autogluon.tabular[all]) (2023.7.22)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.8.2 (from fastai<2.8,>=2.3.1->autogluon.tabular[all])\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==0.8.2->autogluon.tabular[all]) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==0.8.2->autogluon.tabular[all]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==0.8.2->autogluon.tabular[all]) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==0.8.2->autogluon.tabular[all]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==0.8.2->autogluon.tabular[all]) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]) (8.2.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (1.9.2)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_ml_py-12.535.77-py3-none-any.whl (36 kB)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.1.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (3.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.9.2)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (2.11.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.2.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (2.17.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core==0.8.2->autogluon.tabular[all]) (0.5.0)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26274 sha256=1d4c38a74808d8e984efdf5674da28107cd41069779fcd7ac0aa9734de2b7c47\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d0/2c/1e02440645c2318ba03aea99993a44a9108dc8f74de0bd370b\n",
            "Successfully built gpustat\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py, distlib, colorful, virtualenv, urllib3, tensorboardX, pydantic, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, jmespath, grpcio, blessed, nvidia-cudnn-cu11, gpustat, botocore, torch, s3transfer, lightgbm, catboost, aiohttp-cors, torchvision, ray, opencensus, boto3, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.1.1\n",
            "    Uninstalling pydantic-2.1.1:\n",
            "      Successfully uninstalled pydantic-2.1.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.56.2\n",
            "    Uninstalling grpcio-1.56.2:\n",
            "      Successfully uninstalled grpcio-1.56.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.0.0\n",
            "    Uninstalling lightgbm-4.0.0:\n",
            "      Successfully uninstalled lightgbm-4.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 autogluon.common-0.8.2 autogluon.core-0.8.2 autogluon.features-0.8.2 autogluon.tabular-0.8.2 blessed-1.20.0 boto3-1.28.26 botocore-1.31.26 catboost-1.2 colorful-0.5.5 distlib-0.3.7 gpustat-1.1 grpcio-1.50.0 jmespath-1.0.1 lightgbm-3.3.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-ml-py-12.535.77 opencensus-0.11.2 opencensus-context-0.1.3 py-spy-0.3.14 pydantic-1.10.12 ray-2.3.1 s3transfer-0.6.1 tensorboardX-2.6.2 torch-1.13.1 torchvision-0.14.1 urllib3-1.26.16 virtualenv-20.24.3\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon.tabular[all]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon.multimodal==0.8.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OVfsCJQg2XQM",
        "outputId": "7406ff17-a960-414e-d695-9b63ce2c4a0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.multimodal==0.8.2\n",
            "  Downloading autogluon.multimodal-0.8.2-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.3/372.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.10.1)\n",
            "Requirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.2.2)\n",
            "Requirement already satisfied: Pillow<9.6,>=9.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (9.4.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (4.66.0)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.28.26)\n",
            "Requirement already satisfied: requests<3,>=2.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (2.31.0)\n",
            "Collecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.4.0,>=0.2.2 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.17,>=0.9 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.10.0,>=0.9.2 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<1.14,>=1.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.13.1)\n",
            "Requirement already satisfied: torchvision<0.15.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.14.1)\n",
            "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.19.3)\n",
            "Collecting pytorch-lightning<1.10.0,>=1.9.0 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (1.3)\n",
            "Collecting torchmetrics<0.12.0,>=0.11.0 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]<4.27.0,>=4.23.0 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autogluon.core[raytune]==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.features==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.8.2)\n",
            "Requirement already satisfied: autogluon.common==0.8.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.8.2)\n",
            "Collecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2) (2.12.3)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.multimodal==0.8.2) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.multimodal==0.8.2) (67.7.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (3.7.1)\n",
            "Requirement already satisfied: ray[tune]<2.4,>=2.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (2.3.1)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (0.2.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2) (6.0.1)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.26 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.multimodal==0.8.2) (1.31.26)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.multimodal==0.8.2) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.multimodal==0.8.2) (0.6.1)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (2023.6.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.8.2) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2) (23.1.0)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2)\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2) (2023.6.3)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.8.2)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (23.1.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (13.5.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.multimodal==0.8.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.multimodal==0.8.2) (2023.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.8.2) (4.7.1)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.8.2)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21->autogluon.multimodal==0.8.2) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21->autogluon.multimodal==0.8.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21->autogluon.multimodal==0.8.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21->autogluon.multimodal==0.8.2) (2023.7.22)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2) (2023.7.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.multimodal==0.8.2) (3.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (1.50.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (0.41.1)\n",
            "Collecting safetensors (from timm<0.10.0,>=0.9.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2) (11.7.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2) (3.12.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=3.19.6 (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (0.10.9.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (1.0.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (1.4.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (20.24.3)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (2.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (3.1.1)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.6/291.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (2.16.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2) (1.9.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2) (3.2.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (0.3.7)\n",
            "Requirement already satisfied: platformdirs<4,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.4,>=2.3->autogluon.core[raytune]==0.8.2->autogluon.multimodal==0.8.2) (3.10.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2) (2.4.1)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests<3,>=2.21 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools (from autogluon.common==0.8.2->autogluon.multimodal==0.8.2)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm<5,>=4.38 (from autogluon.multimodal==0.8.2)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests[socks] (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21->autogluon.multimodal==0.8.2) (1.7.1)\n",
            "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2)\n",
            "  Downloading aliyun-python-sdk-core-2.13.36.tar.gz (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.multimodal==0.8.2)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2) (2.21)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, seqeval, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=8f668192b46e169fa328be07296c38f812b5e830c95e66ff67a232b90f45569a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=4f27fb7f69d9e492eb3fa87e3a0c42bd897d31ed18d5d625c13cf791b708b253\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=433ee36d8fb47409b0c42a32184dfbacf7d2bcb9d2c9673275e4662545aa9ad7\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.13.36-py3-none-any.whl size=533190 sha256=869e810fa42b9ef05ad4f8b4ab381f520c1ce6a87d09f1332853364327a6cda5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/f4/0e/87c534857132bd3bd2c4465c0b15b4db650cf6c15a876bda34\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31409 sha256=94ba7d29c061fe4e189842a908e85ccc1d8aca893b942fa43b1865fe910f0a2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built antlr4-python3-runtime seqeval oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, crcmod, antlr4-python3-runtime, xxhash, tqdm, setuptools, requests, pytesseract, pyrsistent, pycryptodome, protobuf, ordered-set, omegaconf, nptyping, lightning-utilities, jmespath, dill, colorama, rich, responses, multiprocess, model-index, jsonschema, huggingface-hub, transformers, seqeval, aliyun-python-sdk-core, nlpaug, datasets, aliyun-python-sdk-kms, torchmetrics, pytorch-metric-learning, oss2, evaluate, accelerate, timm, pytorch-lightning, openxlab, opendatalab, openmim, autogluon.multimodal\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.0\n",
            "    Uninstalling tqdm-4.66.0:\n",
            "      Successfully uninstalled tqdm-4.66.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: jmespath\n",
            "    Found existing installation: jmespath 1.0.1\n",
            "    Uninstalling jmespath-1.0.1:\n",
            "      Successfully uninstalled jmespath-1.0.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.5.2\n",
            "    Uninstalling rich-13.5.2:\n",
            "      Successfully uninstalled rich-13.5.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.0\n",
            "    Uninstalling jsonschema-4.19.0:\n",
            "      Successfully uninstalled jsonschema-4.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "yfinance 0.2.27 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.16.0 aliyun-python-sdk-core-2.13.36 aliyun-python-sdk-kms-2.16.1 antlr4-python3-runtime-4.9.3 autogluon.multimodal-0.8.2 colorama-0.4.6 crcmod-1.7 datasets-2.14.4 dill-0.3.7 evaluate-0.3.0 huggingface-hub-0.16.4 jmespath-0.10.0 jsonschema-4.17.3 lightning-utilities-0.9.0 model-index-0.1.11 multiprocess-0.70.15 nlpaug-1.1.11 nptyping-2.4.1 omegaconf-2.2.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.17 ordered-set-4.1.0 oss2-2.17.0 protobuf-3.20.2 pycryptodome-3.18.0 pyrsistent-0.19.3 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 requests-2.28.2 responses-0.18.0 rich-13.4.2 safetensors-0.3.2 sentencepiece-0.1.99 seqeval-1.2.2 setuptools-60.2.0 timm-0.9.5 tokenizers-0.13.3 torchmetrics-0.11.4 tqdm-4.65.2 transformers-4.26.1 xxhash-3.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "google",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from autogluon.tabular import TabularDataset\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "6swz38zUvkXn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3QoX47D29fa",
        "outputId": "798f12fd-617b-495f-a16c-954d83552d11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fake News vs. Official"
      ],
      "metadata": {
        "id": "ktBzfzIYfXy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FT_Transformer (Feature only)"
      ],
      "metadata": {
        "id": "P4xqWKpd6TOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSVs\n",
        "feature_df = pd.read_csv('/content/drive/My Drive/Data/feature_df.csv')\n",
        "print(len(feature_df))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEc1VuXSvtpI",
        "outputId": "445c1edc-5991-4cf9-e2b7-b7ca386734cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter feature_df\n",
        "feature_df = feature_df[['label', 'interestingness', 'sentiment_BERT',\n",
        "                          'sentiment_RoBERTa', 'concreteness', 'valence', 'dominance', 'arousal',\n",
        "                          'sentiment_vader', 'readability', 'lexical_diversity', 'superlatives', 'novelty',\n",
        "                          'average_word_length', 'concreteness_lexical', 'valence_lexical',\n",
        "                          'dominance_lexical', 'arousal_lexical']]"
      ],
      "metadata": {
        "id": "ZZYPUvbtyHHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = feature_df.dropna()\n",
        "len(feature_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhZye3O_gZjS",
        "outputId": "108b5d88-1c52-46f3-8407-b7003910c848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28425"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data accordingly to local splits (seed 42)\n",
        "\n",
        "label_column = 'label'\n",
        "\n",
        "# Assuming feature_df is your dataframe\n",
        "X = feature_df.drop(columns=[label_column])\n",
        "y = feature_df[label_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, if you need the train and test data as TabularDataset:\n",
        "train_data = TabularDataset(pd.concat([X_train, y_train], axis=1))\n",
        "test_data = TabularDataset(pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "id": "8IlTdj5yuFZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For now, only fit the Tabular Transfomer model FT_Transformer\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "hyperparams = {\n",
        "    'FT_TRANSFORMER': {}\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label=label_column, problem_type='binary').fit(train_data, hyperparameters=hyperparams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrn3HrGOuPTl",
        "outputId": "d33f00c1-c1d6-4dfb-d1dc-aa466d4fa1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230811_114557/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230811_114557/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   145.36 GB / 179.07 GB (81.2%)\n",
            "Train Data Rows:    22887\n",
            "Train Data Columns: 17\n",
            "Label Column: label\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6804.61 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.26s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20598, Val Rows: 2289\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'FT_TRANSFORMER': {},\n",
            "}\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: FTTransformer ...\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type                        | Params\n",
            "------------------------------------------------------------------\n",
            "0 | model             | MultimodalFusionTransformer | 825 K \n",
            "1 | validation_metric | MulticlassAccuracy          | 0     \n",
            "2 | loss_func         | CrossEntropyLoss            | 0     \n",
            "------------------------------------------------------------------\n",
            "825 K     Trainable params\n",
            "0         Non-trainable params\n",
            "825 K     Total params\n",
            "1.651     Total estimated model params size (MB)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 80: 'val_accuracy' reached 0.82787 (best 0.82787), saving model to '/content/AutogluonModels/ag-20230811_114557/models/FTTransformer/automm_model/epoch=0-step=80.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 160: 'val_accuracy' reached 0.82569 (best 0.82787), saving model to '/content/AutogluonModels/ag-20230811_114557/models/FTTransformer/automm_model/epoch=0-step=160.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 241: 'val_accuracy' reached 0.83355 (best 0.83355), saving model to '/content/AutogluonModels/ag-20230811_114557/models/FTTransformer/automm_model/epoch=1-step=241.ckpt' as top 3\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
            "\t0.8336\t = Validation score   (accuracy)\n",
            "\t12.59s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8336\t = Validation score   (accuracy)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 13.06s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230811_114557/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_test = test_data[label_column]\n",
        "test_data_nolab = test_data.drop(labels=[label_column], axis=1)\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "\n",
        "# Evaluate the performance\n",
        "performance = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred)\n",
        "print(performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBuIbUksvBIA",
        "outputId": "ab41a944-6bc0-41fc-b2ff-55af9b1ad3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Evaluation: accuracy on test data: 0.8715484096469766\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.8715484096469766,\n",
            "    \"balanced_accuracy\": 0.8682859518479873,\n",
            "    \"mcc\": 0.7397404405884439,\n",
            "    \"f1\": 0.8536731037228749,\n",
            "    \"precision\": 0.8708367181153533,\n",
            "    \"recall\": 0.837172979304959\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8715484096469766, 'balanced_accuracy': 0.8682859518479873, 'mcc': 0.7397404405884439, 'f1': 0.8536731037228749, 'precision': 0.8708367181153533, 'recall': 0.837172979304959}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "901T4aC_u9-I",
        "outputId": "37a0e326-b423-494d-9b90-2576e196cef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 17 features using 5000 rows with 5 shuffle sets...\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "\t25.3s\t= Expected runtime (5.06s per shuffle set)\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_091859/models/FTTransformer/automm_model/model.ckpt\n",
            "\t21.94s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      importance    stddev       p_value  n  p99_high  \\\n",
              "sentiment_RoBERTa        0.06320  0.003603  1.261778e-06  5  0.070618   \n",
              "sentiment_BERT           0.05380  0.003707  2.687087e-06  5  0.061432   \n",
              "concreteness             0.02800  0.003865  4.249086e-05  5  0.035959   \n",
              "arousal                  0.02664  0.003798  4.828087e-05  5  0.034461   \n",
              "dominance                0.02584  0.003419  3.592715e-05  5  0.032879   \n",
              "dominance_lexical        0.02416  0.001322  1.071875e-06  5  0.026882   \n",
              "novelty                  0.02388  0.003032  3.052019e-05  5  0.030123   \n",
              "valence                  0.02372  0.003068  3.284439e-05  5  0.030037   \n",
              "average_word_length      0.02252  0.002129  9.469576e-06  5  0.026903   \n",
              "valence_lexical          0.02160  0.003547  8.419248e-05  5  0.028903   \n",
              "arousal_lexical          0.02148  0.000965  4.883230e-07  5  0.023468   \n",
              "lexical_diversity        0.01808  0.001553  6.469660e-06  5  0.021278   \n",
              "sentiment_vader          0.01644  0.002313  4.577041e-05  5  0.021202   \n",
              "concreteness_lexical     0.01496  0.003160  2.254246e-04  5  0.021467   \n",
              "readability              0.01244  0.001646  3.590307e-05  5  0.015828   \n",
              "interestingness          0.01148  0.001474  3.188965e-05  5  0.014515   \n",
              "superlatives             0.00428  0.002243  6.493793e-03  5  0.008899   \n",
              "\n",
              "                       p99_low  \n",
              "sentiment_RoBERTa     0.055782  \n",
              "sentiment_BERT        0.046168  \n",
              "concreteness          0.020041  \n",
              "arousal               0.018819  \n",
              "dominance             0.018801  \n",
              "dominance_lexical     0.021438  \n",
              "novelty               0.017637  \n",
              "valence               0.017403  \n",
              "average_word_length   0.018137  \n",
              "valence_lexical       0.014297  \n",
              "arousal_lexical       0.019492  \n",
              "lexical_diversity     0.014882  \n",
              "sentiment_vader       0.011678  \n",
              "concreteness_lexical  0.008453  \n",
              "readability           0.009052  \n",
              "interestingness       0.008445  \n",
              "superlatives         -0.000339  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-2fc889fb-7453-4919-b1d2-48983e5c9805\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentiment_RoBERTa</th>\n",
              "      <td>0.06320</td>\n",
              "      <td>0.003603</td>\n",
              "      <td>1.261778e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.070618</td>\n",
              "      <td>0.055782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_BERT</th>\n",
              "      <td>0.05380</td>\n",
              "      <td>0.003707</td>\n",
              "      <td>2.687087e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.061432</td>\n",
              "      <td>0.046168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness</th>\n",
              "      <td>0.02800</td>\n",
              "      <td>0.003865</td>\n",
              "      <td>4.249086e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.035959</td>\n",
              "      <td>0.020041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal</th>\n",
              "      <td>0.02664</td>\n",
              "      <td>0.003798</td>\n",
              "      <td>4.828087e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.034461</td>\n",
              "      <td>0.018819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance</th>\n",
              "      <td>0.02584</td>\n",
              "      <td>0.003419</td>\n",
              "      <td>3.592715e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.032879</td>\n",
              "      <td>0.018801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance_lexical</th>\n",
              "      <td>0.02416</td>\n",
              "      <td>0.001322</td>\n",
              "      <td>1.071875e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.026882</td>\n",
              "      <td>0.021438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>novelty</th>\n",
              "      <td>0.02388</td>\n",
              "      <td>0.003032</td>\n",
              "      <td>3.052019e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.030123</td>\n",
              "      <td>0.017637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence</th>\n",
              "      <td>0.02372</td>\n",
              "      <td>0.003068</td>\n",
              "      <td>3.284439e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.030037</td>\n",
              "      <td>0.017403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_word_length</th>\n",
              "      <td>0.02252</td>\n",
              "      <td>0.002129</td>\n",
              "      <td>9.469576e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.026903</td>\n",
              "      <td>0.018137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence_lexical</th>\n",
              "      <td>0.02160</td>\n",
              "      <td>0.003547</td>\n",
              "      <td>8.419248e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.028903</td>\n",
              "      <td>0.014297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal_lexical</th>\n",
              "      <td>0.02148</td>\n",
              "      <td>0.000965</td>\n",
              "      <td>4.883230e-07</td>\n",
              "      <td>5</td>\n",
              "      <td>0.023468</td>\n",
              "      <td>0.019492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexical_diversity</th>\n",
              "      <td>0.01808</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>6.469660e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021278</td>\n",
              "      <td>0.014882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_vader</th>\n",
              "      <td>0.01644</td>\n",
              "      <td>0.002313</td>\n",
              "      <td>4.577041e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021202</td>\n",
              "      <td>0.011678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness_lexical</th>\n",
              "      <td>0.01496</td>\n",
              "      <td>0.003160</td>\n",
              "      <td>2.254246e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021467</td>\n",
              "      <td>0.008453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>readability</th>\n",
              "      <td>0.01244</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>3.590307e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.015828</td>\n",
              "      <td>0.009052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>interestingness</th>\n",
              "      <td>0.01148</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>3.188965e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.014515</td>\n",
              "      <td>0.008445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>superlatives</th>\n",
              "      <td>0.00428</td>\n",
              "      <td>0.002243</td>\n",
              "      <td>6.493793e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008899</td>\n",
              "      <td>-0.000339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fc889fb-7453-4919-b1d2-48983e5c9805')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2d6fc050-d60d-42a4-a398-22e9d51225fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d6fc050-d60d-42a4-a398-22e9d51225fd')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2d6fc050-d60d-42a4-a398-22e9d51225fd button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fc889fb-7453-4919-b1d2-48983e5c9805 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fc889fb-7453-4919-b1d2-48983e5c9805');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Predictor"
      ],
      "metadata": {
        "id": "QQ45nUx3APON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For for testing, what performance do we get when using an ensemble model?\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "predictor = TabularPredictor(label=label_column, problem_type='binary').fit(train_data, hyperparameters='default')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZlsYr1EAZbs",
        "outputId": "42f93cc9-b319-43d3-8b11-3a687424728c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230811_114622/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230811_114622/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   145.35 GB / 179.07 GB (81.2%)\n",
            "Train Data Rows:    22887\n",
            "Train Data Columns: 17\n",
            "Label Column: label\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6807.07 MB\n",
            "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t0.1s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.11 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20598, Val Rows: 2289\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.8204\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.8283\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.8611\t = Validation score   (accuracy)\n",
            "\t2.87s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\tvalid_set's binary_error: 0.13412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.8659\t = Validation score   (accuracy)\n",
            "\t4.57s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.8536\t = Validation score   (accuracy)\n",
            "\t18.97s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.855\t = Validation score   (accuracy)\n",
            "\t21.62s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.8615\t = Validation score   (accuracy)\n",
            "\t22.12s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.8545\t = Validation score   (accuracy)\n",
            "\t3.66s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.8536\t = Validation score   (accuracy)\n",
            "\t6.61s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.8619\t = Validation score   (accuracy)\n",
            "\t27.32s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.8689\t = Validation score   (accuracy)\n",
            "\t6.58s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.8515\t = Validation score   (accuracy)\n",
            "\t32.0s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.8694\t = Validation score   (accuracy)\n",
            "\t13.12s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8733\t = Validation score   (accuracy)\n",
            "\t1.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 166.09s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230811_114622/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_test = test_data[label_column]\n",
        "test_data_nolab = test_data.drop(labels=[label_column], axis=1)\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "\n",
        "# Evaluate the performance\n",
        "performance = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred)\n",
        "print(performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM6sGuKrAbSK",
        "outputId": "66d1770a-9a2d-4341-fdf2-2ec15648daf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: accuracy on test data: 0.8771408598392171\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.8771408598392171,\n",
            "    \"balanced_accuracy\": 0.8751264464991567,\n",
            "    \"mcc\": 0.7512848954854175,\n",
            "    \"f1\": 0.8618045999606841,\n",
            "    \"precision\": 0.8677751385589866,\n",
            "    \"recall\": 0.8559156579461148\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8771408598392171, 'balanced_accuracy': 0.8751264464991567, 'mcc': 0.7512848954854175, 'f1': 0.8618045999606841, 'precision': 0.8677751385589866, 'recall': 0.8559156579461148}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "STuxCwx6AccD",
        "outputId": "f2f63a90-b8ea-4f50-8c8e-056bdc268490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 17 features using 5000 rows with 5 shuffle sets...\n",
            "\t213.1s\t= Expected runtime (42.62s per shuffle set)\n",
            "\t178.09s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      importance    stddev       p_value  n  p99_high  \\\n",
              "sentiment_RoBERTa        0.05092  0.003303  2.113505e-06  5  0.057722   \n",
              "sentiment_BERT           0.05068  0.003746  3.555634e-06  5  0.058393   \n",
              "concreteness             0.01940  0.001778  8.365698e-06  5  0.023060   \n",
              "novelty                  0.01724  0.002224  3.253213e-05  5  0.021820   \n",
              "valence                  0.01684  0.001740  1.348860e-05  5  0.020423   \n",
              "dominance_lexical        0.01460  0.001749  2.426305e-05  5  0.018202   \n",
              "arousal                  0.01432  0.001770  2.743215e-05  5  0.017964   \n",
              "sentiment_vader          0.01292  0.000687  9.558277e-07  5  0.014335   \n",
              "dominance                0.01256  0.002508  1.809307e-04  5  0.017723   \n",
              "average_word_length      0.01244  0.001532  2.707452e-05  5  0.015595   \n",
              "lexical_diversity        0.01148  0.003251  6.960621e-04  5  0.018175   \n",
              "concreteness_lexical     0.00976  0.001621  8.806918e-05  5  0.013098   \n",
              "readability              0.00948  0.001863  1.702398e-04  5  0.013317   \n",
              "valence_lexical          0.00944  0.001723  1.274022e-04  5  0.012987   \n",
              "arousal_lexical          0.00832  0.001942  3.318323e-04  5  0.012319   \n",
              "interestingness          0.00512  0.001316  4.807011e-04  5  0.007830   \n",
              "superlatives             0.00312  0.001803  9.006742e-03  5  0.006833   \n",
              "\n",
              "                       p99_low  \n",
              "sentiment_RoBERTa     0.044118  \n",
              "sentiment_BERT        0.042967  \n",
              "concreteness          0.015740  \n",
              "novelty               0.012660  \n",
              "valence               0.013257  \n",
              "dominance_lexical     0.010998  \n",
              "arousal               0.010676  \n",
              "sentiment_vader       0.011505  \n",
              "dominance             0.007397  \n",
              "average_word_length   0.009285  \n",
              "lexical_diversity     0.004785  \n",
              "concreteness_lexical  0.006422  \n",
              "readability           0.005643  \n",
              "valence_lexical       0.005893  \n",
              "arousal_lexical       0.004321  \n",
              "interestingness       0.002410  \n",
              "superlatives         -0.000593  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e433cbe4-2070-4185-9d2a-bf21333638f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sentiment_RoBERTa</th>\n",
              "      <td>0.05092</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>2.113505e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.057722</td>\n",
              "      <td>0.044118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_BERT</th>\n",
              "      <td>0.05068</td>\n",
              "      <td>0.003746</td>\n",
              "      <td>3.555634e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.058393</td>\n",
              "      <td>0.042967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness</th>\n",
              "      <td>0.01940</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>8.365698e-06</td>\n",
              "      <td>5</td>\n",
              "      <td>0.023060</td>\n",
              "      <td>0.015740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>novelty</th>\n",
              "      <td>0.01724</td>\n",
              "      <td>0.002224</td>\n",
              "      <td>3.253213e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.021820</td>\n",
              "      <td>0.012660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence</th>\n",
              "      <td>0.01684</td>\n",
              "      <td>0.001740</td>\n",
              "      <td>1.348860e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.020423</td>\n",
              "      <td>0.013257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance_lexical</th>\n",
              "      <td>0.01460</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>2.426305e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.018202</td>\n",
              "      <td>0.010998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal</th>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>2.743215e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.017964</td>\n",
              "      <td>0.010676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_vader</th>\n",
              "      <td>0.01292</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>9.558277e-07</td>\n",
              "      <td>5</td>\n",
              "      <td>0.014335</td>\n",
              "      <td>0.011505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance</th>\n",
              "      <td>0.01256</td>\n",
              "      <td>0.002508</td>\n",
              "      <td>1.809307e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.017723</td>\n",
              "      <td>0.007397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_word_length</th>\n",
              "      <td>0.01244</td>\n",
              "      <td>0.001532</td>\n",
              "      <td>2.707452e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.015595</td>\n",
              "      <td>0.009285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexical_diversity</th>\n",
              "      <td>0.01148</td>\n",
              "      <td>0.003251</td>\n",
              "      <td>6.960621e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.018175</td>\n",
              "      <td>0.004785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness_lexical</th>\n",
              "      <td>0.00976</td>\n",
              "      <td>0.001621</td>\n",
              "      <td>8.806918e-05</td>\n",
              "      <td>5</td>\n",
              "      <td>0.013098</td>\n",
              "      <td>0.006422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>readability</th>\n",
              "      <td>0.00948</td>\n",
              "      <td>0.001863</td>\n",
              "      <td>1.702398e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.013317</td>\n",
              "      <td>0.005643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence_lexical</th>\n",
              "      <td>0.00944</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>1.274022e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>0.005893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal_lexical</th>\n",
              "      <td>0.00832</td>\n",
              "      <td>0.001942</td>\n",
              "      <td>3.318323e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.012319</td>\n",
              "      <td>0.004321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>interestingness</th>\n",
              "      <td>0.00512</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>4.807011e-04</td>\n",
              "      <td>5</td>\n",
              "      <td>0.007830</td>\n",
              "      <td>0.002410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>superlatives</th>\n",
              "      <td>0.00312</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>9.006742e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006833</td>\n",
              "      <td>-0.000593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e433cbe4-2070-4185-9d2a-bf21333638f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-bbecbfe4-f29c-49b9-bb2f-19be58b46bec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbecbfe4-f29c-49b9-bb2f-19be58b46bec')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-bbecbfe4-f29c-49b9-bb2f-19be58b46bec button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e433cbe4-2070-4185-9d2a-bf21333638f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e433cbe4-2070-4185-9d2a-bf21333638f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multimodal (Feature + Text)"
      ],
      "metadata": {
        "id": "o9OcoLSC6bEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSVs\n",
        "feature_df = pd.read_csv('/content/drive/My Drive/Data/feature_df.csv')\n",
        "print(len(feature_df))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9U66P8P6cPV",
        "outputId": "f1f1fbd7-2504-4450-ac9f-2edc5bfb1ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter feature_df\n",
        "feature_df = feature_df[['label', 'preprocessed','interestingness', 'sentiment_BERT',\n",
        "                          'sentiment_RoBERTa', 'concreteness', 'valence', 'dominance', 'arousal',\n",
        "                          'sentiment_vader', 'readability', 'lexical_diversity', 'superlatives', 'novelty',\n",
        "                          'average_word_length', 'concreteness_lexical', 'valence_lexical',\n",
        "                          'dominance_lexical', 'arousal_lexical']]"
      ],
      "metadata": {
        "id": "M4TWupWI6hIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data accordingly to Visual Studio splits (seed 42)\n",
        "\n",
        "label_column = 'label'\n",
        "\n",
        "# Assuming feature_df is your dataframe\n",
        "X = feature_df.drop(columns=[label_column])\n",
        "y = feature_df[label_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, if you need the train and test data as TabularDataset:\n",
        "train_data = TabularDataset(pd.concat([X_train, y_train], axis=1))\n",
        "test_data = TabularDataset(pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "id": "SlLydzJ06jB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "predictor = TabularPredictor(label=label_column, problem_type='binary').fit(train_data, hyperparameters='multimodal')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "62623bde87a444e987279486f1aa42a3",
            "e1d2a70d3bcf4f768bdb55208d142368",
            "27e53acd70584abab4481469e0d3c87e",
            "fe00ac006fe243c18ee60cfeabccabea",
            "f7bd61876cb44f86b313245d0fa7dd5e",
            "f989db61681647de955cbd82d8697531",
            "b763985558624c4a8ecf892e866e66f2",
            "dfa7551428e549229d99a51f9c50cf3e",
            "4886b6096d2f439cab4dd0c6eb6029da",
            "d69381aef9674192934ab5a68879ea9d",
            "80b98ff6cc964d22a24414245c1c0706",
            "cbb0db3870564407a12a594cb7e87839",
            "002744d6f3b34be6b4bdc17dd172a74f",
            "95baed6cdf204dcaa3111af5e0ce7c33",
            "2e258c82fcf1409588c791ba4ce6c80d",
            "493eb89b793b4a3ab52a3e57ac48e95b",
            "0de562d50f364f899a8b5f4f737409a6",
            "2ac2d5b74da34b6c914531a3e8a0e7d9",
            "51a60a47fb7a4a47acead5087237d1ad",
            "33319ede618e4c2698e7828a025e2b41",
            "34d0c88b802441e8a079dc3140738abc",
            "266b0c31b7514463a364d31076e27802",
            "a82d371b33d445afb1ef37792c75d676",
            "dd45d0035b1647449b8a272b3d4237ac",
            "1caed4b35555492ca1a4b9ac3d4eb69d",
            "be1926f35a934b758fce3162e5d91e25",
            "7dd1739dff5a49cda29c4a69924ac0f5",
            "46174b0b06b24c06ac3e5df334d110a2",
            "836fd738b70944988b5a93f025afd914",
            "875946d7b2bb438bb1fcb5df5fca4ad3",
            "91c94de663e7462bae017b2325881201",
            "0347ce3292c24ff897793ff66a564893",
            "4b8a300238b04c42be42376981d33eac",
            "3442f384b3cf493a9c57d76006da6242",
            "aebb25915cae48458076cd3a22fb62d0",
            "2ae0260f40404fbd87a388b5d5b86739",
            "0ccd0f781689451f8bb861c37f67d8d1",
            "789bcb8d79e64ea49ed0876ede4bcc5a",
            "0ba5e4353c504f2bafe8b496bc2d83bd",
            "cae5643d0a9a444a91fbc8c7804ab375",
            "e0e0602407c24c07937d897a47d27322",
            "61717f49688f4b1a8caf99ca12d83bac",
            "be26252481534baf949d321dc5955767",
            "9c1ea0dd18d645abbbe86b7add71d3d8",
            "f3e46deb86394e6b8bd910a1260ffb77",
            "5009481405f443aba7142a25125ed381",
            "a1bab205b93743d68842e441a649d718",
            "84414f141c1c4f88bdb207c0f9fbe8f8",
            "bb8f4c482498466494082d4cfaac7e23",
            "d166ce41aea54429b8aa9a149b6cab0d",
            "ec907684a7f94a07afde6019dd062ec3",
            "55b2d2932a9b437e99224b79a256eb77",
            "b801b9f38f3b43a88854ae2457380007",
            "f0a8e8e898b74315b40cc76c36baf384",
            "b00da1b6de1245f297ef8f20273d75c8"
          ]
        },
        "id": "qygkzlJ0_-Ti",
        "outputId": "60ce1245-1ff6-437e-bd0f-43573a268b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230811_094944/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230811_094944/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   146.32 GB / 179.07 GB (81.7%)\n",
            "Train Data Rows:    22887\n",
            "Train Data Columns: 18\n",
            "Label Column: label\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    8365.56 MB\n",
            "\tTrain Data (Original)  Memory Usage: 10.53 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tFitting RenameFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['preprocessed']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 4431\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 4431 to 1165 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])          :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t\t('object', ['text']) :  1 | ['preprocessed']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', ['text_as_category'])  :    1 | ['preprocessed']\n",
            "\t\t('float', [])                       :   13 | ['interestingness', 'concreteness', 'valence', 'dominance', 'arousal', ...]\n",
            "\t\t('int', [])                         :    4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t\t('int', ['binned', 'text_special']) :    6 | ['preprocessed.char_count', 'preprocessed.word_count', 'preprocessed.lower_ratio', 'preprocessed.digit_ratio', 'preprocessed.special_ratio', ...]\n",
            "\t\t('int', ['text_ngram'])             : 1149 | ['__nlp__.2020confusion', '__nlp__.about', '__nlp__.about covid19', '__nlp__.about the', '__nlp__.access', ...]\n",
            "\t\t('object', ['text'])                :    1 | ['preprocessed_raw_text']\n",
            "\t26.5s = Fit runtime\n",
            "\t18 features in original data used to generate 1174 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 63.37 MB (0.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 26.94s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20598, Val Rows: 2289\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'AG_AUTOMM': {},\n",
            "\t'VW': {},\n",
            "}\n",
            "Fitting 8 L1 models ...\n",
            "Fitting model: LightGBM ...\n",
            "\t0.9891\t = Validation score   (accuracy)\n",
            "\t18.82s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.9882\t = Validation score   (accuracy)\n",
            "\t14.65s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.9843\t = Validation score   (accuracy)\n",
            "\t48.33s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.9882\t = Validation score   (accuracy)\n",
            "\t118.71s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.9401\t = Validation score   (accuracy)\n",
            "\t46.51s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: VowpalWabbit ...\n",
            "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
            "\t\t`import vowpalwabbit` failed.\n",
            "A quick tip is to install via `pip install vowpalwabbit>=9,<9.5\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.9856\t = Validation score   (accuracy)\n",
            "\t24.71s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: MultiModalPredictor ...\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62623bde87a444e987279486f1aa42a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbb0db3870564407a12a594cb7e87839"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/pytorch_model.bin\n",
            "Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of ElectraModel were initialized from the model checkpoint at google/electra-base-discriminator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a82d371b33d445afb1ef37792c75d676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3442f384b3cf493a9c57d76006da6242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3e46deb86394e6b8bd910a1260ffb77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--electra-base-discriminator/snapshots/1b48ef100dac4676d84125a8a7b7ab7c51e00386/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-base-discriminator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "Configuration saved in /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "tokenizer config file saved in /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/tokenizer_config.json\n",
            "Special tokens file saved in /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/special_tokens_map.json\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type                | Params\n",
            "----------------------------------------------------------\n",
            "0 | model             | MultimodalFusionMLP | 109 M \n",
            "1 | validation_metric | MulticlassAccuracy  | 0     \n",
            "2 | loss_func         | CrossEntropyLoss    | 0     \n",
            "----------------------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "219.571   Total estimated model params size (MB)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 80: 'val_accuracy' reached 0.97335 (best 0.97335), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=0-step=80.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 160: 'val_accuracy' reached 0.96898 (best 0.97335), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=0-step=160.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 241: 'val_accuracy' reached 0.98558 (best 0.98558), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=1-step=241.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 321: 'val_accuracy' reached 0.98864 (best 0.98864), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=1-step=321.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 402: 'val_accuracy' reached 0.98733 (best 0.98864), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=2-step=402.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 482: 'val_accuracy' reached 0.99301 (best 0.99301), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=2-step=482.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 563: 'val_accuracy' reached 0.99345 (best 0.99345), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=3-step=563.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 643: 'val_accuracy' reached 0.99388 (best 0.99388), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=3-step=643.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 724: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 804: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 885: 'val_accuracy' reached 0.99432 (best 0.99432), saving model to '/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/epoch=5-step=885.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 965: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1046: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1126: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1207: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1287: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1368: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1448: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 1529: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 1609: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Configuration saved in AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "tokenizer config file saved in AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/tokenizer_config.json\n",
            "Special tokens file saved in AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/special_tokens_map.json\n",
            "\t0.9943\t = Validation score   (accuracy)\n",
            "\t3008.43s\t = Training   runtime\n",
            "\t5.89s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.9952\t = Validation score   (accuracy)\n",
            "\t1.53s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 3317.46s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230811_094944/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "gOGv6P9jWCZN",
        "outputId": "7e5d91e6-f791-452b-d19b-9a0b3d83d29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L2   0.995194       6.098720  3128.676885                0.007020           1.533336            2       True          8\n",
            "1  MultiModalPredictor   0.994321       5.888294  3008.431234                5.888294        3008.431234            1       True          7\n",
            "2             LightGBM   0.989078       0.234561    18.818745                0.234561          18.818745            1       True          1\n",
            "3           LightGBMXT   0.988204       0.126068    14.646055                0.126068          14.646055            1       True          2\n",
            "4              XGBoost   0.988204       0.203406   118.712315                0.203406         118.712315            1       True          4\n",
            "5        LightGBMLarge   0.985583       0.344923    24.712695                0.344923          24.712695            1       True          6\n",
            "6             CatBoost   0.984273       0.072487    48.330128                0.072487          48.330128            1       True          3\n",
            "7       NeuralNetTorch   0.940149       0.021779    46.506488                0.021779          46.506488            1       True          5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 model  score_val  pred_time_val     fit_time  \\\n",
              "0  WeightedEnsemble_L2   0.995194       6.098720  3128.676885   \n",
              "1  MultiModalPredictor   0.994321       5.888294  3008.431234   \n",
              "2             LightGBM   0.989078       0.234561    18.818745   \n",
              "3           LightGBMXT   0.988204       0.126068    14.646055   \n",
              "4              XGBoost   0.988204       0.203406   118.712315   \n",
              "5        LightGBMLarge   0.985583       0.344923    24.712695   \n",
              "6             CatBoost   0.984273       0.072487    48.330128   \n",
              "7       NeuralNetTorch   0.940149       0.021779    46.506488   \n",
              "\n",
              "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                0.007020           1.533336            2       True   \n",
              "1                5.888294        3008.431234            1       True   \n",
              "2                0.234561          18.818745            1       True   \n",
              "3                0.126068          14.646055            1       True   \n",
              "4                0.203406         118.712315            1       True   \n",
              "5                0.344923          24.712695            1       True   \n",
              "6                0.072487          48.330128            1       True   \n",
              "7                0.021779          46.506488            1       True   \n",
              "\n",
              "   fit_order  \n",
              "0          8  \n",
              "1          7  \n",
              "2          1  \n",
              "3          2  \n",
              "4          4  \n",
              "5          6  \n",
              "6          3  \n",
              "7          5  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ab857b6b-a099-4f90-9dec-408cbf4a4cef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.995194</td>\n",
              "      <td>6.098720</td>\n",
              "      <td>3128.676885</td>\n",
              "      <td>0.007020</td>\n",
              "      <td>1.533336</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultiModalPredictor</td>\n",
              "      <td>0.994321</td>\n",
              "      <td>5.888294</td>\n",
              "      <td>3008.431234</td>\n",
              "      <td>5.888294</td>\n",
              "      <td>3008.431234</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.989078</td>\n",
              "      <td>0.234561</td>\n",
              "      <td>18.818745</td>\n",
              "      <td>0.234561</td>\n",
              "      <td>18.818745</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.988204</td>\n",
              "      <td>0.126068</td>\n",
              "      <td>14.646055</td>\n",
              "      <td>0.126068</td>\n",
              "      <td>14.646055</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.988204</td>\n",
              "      <td>0.203406</td>\n",
              "      <td>118.712315</td>\n",
              "      <td>0.203406</td>\n",
              "      <td>118.712315</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.985583</td>\n",
              "      <td>0.344923</td>\n",
              "      <td>24.712695</td>\n",
              "      <td>0.344923</td>\n",
              "      <td>24.712695</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.984273</td>\n",
              "      <td>0.072487</td>\n",
              "      <td>48.330128</td>\n",
              "      <td>0.072487</td>\n",
              "      <td>48.330128</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.940149</td>\n",
              "      <td>0.021779</td>\n",
              "      <td>46.506488</td>\n",
              "      <td>0.021779</td>\n",
              "      <td>46.506488</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab857b6b-a099-4f90-9dec-408cbf4a4cef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-86529798-4d1a-47b5-8de0-bfc6ecdc073c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86529798-4d1a-47b5-8de0-bfc6ecdc073c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-86529798-4d1a-47b5-8de0-bfc6ecdc073c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab857b6b-a099-4f90-9dec-408cbf4a4cef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab857b6b-a099-4f90-9dec-408cbf4a4cef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_test = test_data[label_column]\n",
        "test_data_nolab = test_data.drop(labels=[label_column], axis=1)\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "\n",
        "# Evaluate the performance\n",
        "performance = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred)\n",
        "print(performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiCIdNFxAEeu",
        "outputId": "1e419b4b-2338-4ffb-ab7a-8a4d97680a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "Evaluation: accuracy on test data: 0.993184201328207\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.993184201328207,\n",
            "    \"balanced_accuracy\": 0.9926451959100819,\n",
            "    \"mcc\": 0.9862426384479229,\n",
            "    \"f1\": 0.992348440258976,\n",
            "    \"precision\": 0.9972397476340694,\n",
            "    \"recall\": 0.9875048809058962\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.993184201328207, 'balanced_accuracy': 0.9926451959100819, 'mcc': 0.9862426384479229, 'f1': 0.992348440258976, 'precision': 0.9972397476340694, 'recall': 0.9875048809058962}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It almost entirely relies on the text\n",
        "predictor.feature_importance(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "shI5qHxMAfyY",
        "outputId": "8c1ba134-a6b8-43de-c951-6ae3ff62a3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 18 features using 5000 rows with 5 shuffle sets...\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "\t1302.53s\t= Expected runtime (260.51s per shuffle set)\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_094944/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "\t891.27s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      importance    stddev       p_value  n  p99_high  \\\n",
              "preprocessed             0.48036  0.007790  8.297882e-09  5  0.496400   \n",
              "novelty                  0.00044  0.000297  1.473566e-02  5  0.001051   \n",
              "readability              0.00044  0.000219  5.449849e-03  5  0.000891   \n",
              "dominance                0.00036  0.000261  1.834099e-02  5  0.000897   \n",
              "lexical_diversity        0.00024  0.000261  5.435048e-02  5  0.000777   \n",
              "valence                  0.00024  0.000167  1.633896e-02  5  0.000585   \n",
              "arousal                  0.00024  0.000167  1.633896e-02  5  0.000585   \n",
              "dominance_lexical        0.00016  0.000167  4.965034e-02  5  0.000505   \n",
              "sentiment_vader          0.00012  0.000179  1.040000e-01  5  0.000488   \n",
              "superlatives             0.00008  0.000110  8.890390e-02  5  0.000306   \n",
              "average_word_length      0.00008  0.000110  8.890390e-02  5  0.000306   \n",
              "arousal_lexical          0.00008  0.000110  8.890390e-02  5  0.000306   \n",
              "valence_lexical          0.00004  0.000089  1.869505e-01  5  0.000224   \n",
              "concreteness             0.00004  0.000219  3.520000e-01  5  0.000491   \n",
              "interestingness         -0.00004  0.000089  8.130495e-01  5  0.000144   \n",
              "concreteness_lexical    -0.00004  0.000167  6.893459e-01  5  0.000305   \n",
              "sentiment_BERT          -0.00004  0.000261  6.255658e-01  5  0.000497   \n",
              "sentiment_RoBERTa       -0.00012  0.000110  9.647580e-01  5  0.000106   \n",
              "\n",
              "                       p99_low  \n",
              "preprocessed          0.464320  \n",
              "novelty              -0.000171  \n",
              "readability          -0.000011  \n",
              "dominance            -0.000177  \n",
              "lexical_diversity    -0.000297  \n",
              "valence              -0.000105  \n",
              "arousal              -0.000105  \n",
              "dominance_lexical    -0.000185  \n",
              "sentiment_vader      -0.000248  \n",
              "superlatives         -0.000146  \n",
              "average_word_length  -0.000146  \n",
              "arousal_lexical      -0.000146  \n",
              "valence_lexical      -0.000144  \n",
              "concreteness         -0.000411  \n",
              "interestingness      -0.000224  \n",
              "concreteness_lexical -0.000385  \n",
              "sentiment_BERT       -0.000577  \n",
              "sentiment_RoBERTa    -0.000346  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-55728724-bc3e-4ffd-8e48-3df8fe349898\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "      <th>stddev</th>\n",
              "      <th>p_value</th>\n",
              "      <th>n</th>\n",
              "      <th>p99_high</th>\n",
              "      <th>p99_low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>preprocessed</th>\n",
              "      <td>0.48036</td>\n",
              "      <td>0.007790</td>\n",
              "      <td>8.297882e-09</td>\n",
              "      <td>5</td>\n",
              "      <td>0.496400</td>\n",
              "      <td>0.464320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>novelty</th>\n",
              "      <td>0.00044</td>\n",
              "      <td>0.000297</td>\n",
              "      <td>1.473566e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>-0.000171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>readability</th>\n",
              "      <td>0.00044</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>5.449849e-03</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>-0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance</th>\n",
              "      <td>0.00036</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>1.834099e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>-0.000177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lexical_diversity</th>\n",
              "      <td>0.00024</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>5.435048e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>-0.000297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence</th>\n",
              "      <td>0.00024</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>1.633896e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>-0.000105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal</th>\n",
              "      <td>0.00024</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>1.633896e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>-0.000105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominance_lexical</th>\n",
              "      <td>0.00016</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>4.965034e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000505</td>\n",
              "      <td>-0.000185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_vader</th>\n",
              "      <td>0.00012</td>\n",
              "      <td>0.000179</td>\n",
              "      <td>1.040000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>-0.000248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>superlatives</th>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>8.890390e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>-0.000146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_word_length</th>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>8.890390e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>-0.000146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arousal_lexical</th>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>8.890390e-02</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>-0.000146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valence_lexical</th>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>1.869505e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>-0.000144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness</th>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.000219</td>\n",
              "      <td>3.520000e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>-0.000411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>interestingness</th>\n",
              "      <td>-0.00004</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>8.130495e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>-0.000224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concreteness_lexical</th>\n",
              "      <td>-0.00004</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>6.893459e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>-0.000385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_BERT</th>\n",
              "      <td>-0.00004</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>6.255658e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000497</td>\n",
              "      <td>-0.000577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_RoBERTa</th>\n",
              "      <td>-0.00012</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>9.647580e-01</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>-0.000346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55728724-bc3e-4ffd-8e48-3df8fe349898')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e1f0268c-ada4-4d75-ad9c-c7860a5ceb34\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1f0268c-ada4-4d75-ad9c-c7860a5ceb34')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e1f0268c-ada4-4d75-ad9c-c7860a5ceb34 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55728724-bc3e-4ffd-8e48-3df8fe349898 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55728724-bc3e-4ffd-8e48-3df8fe349898');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interestingness"
      ],
      "metadata": {
        "id": "rNxK101yfij_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSVs\n",
        "feature_df = pd.read_csv('/content/drive/My Drive/Data/feature_df.csv')\n",
        "print(len(feature_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubpzXtugfjec",
        "outputId": "0510cbfe-5f48-4a3a-dd13-75b25db75670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter feature_df\n",
        "feature_df = feature_df[['interestingness', 'sentiment_BERT',\n",
        "                          'sentiment_RoBERTa', 'concreteness', 'valence', 'dominance', 'arousal',\n",
        "                          'sentiment_vader', 'readability', 'lexical_diversity', 'superlatives', 'novelty',\n",
        "                          'average_word_length', 'concreteness_lexical', 'valence_lexical',\n",
        "                          'dominance_lexical', 'arousal_lexical']]"
      ],
      "metadata": {
        "id": "a5wuJePrfm7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = feature_df.dropna()\n",
        "len(feature_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sArhJzWqf3P0",
        "outputId": "bea85488-21ee-40b4-ca9f-bdbdbb175593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28425"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FT_Transformer (Features Only)"
      ],
      "metadata": {
        "id": "ZAc7E27egO2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data accordingly to Visual Studio splits (seed 42)\n",
        "\n",
        "label_column = 'interestingness'\n",
        "\n",
        "# Assuming feature_df is your dataframe\n",
        "X = feature_df.drop(columns=[label_column])\n",
        "y = feature_df[label_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, if you need the train and test data as TabularDataset:\n",
        "train_data = TabularDataset(pd.concat([X_train, y_train], axis=1))\n",
        "test_data = TabularDataset(pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "id": "bPBFORsWfoUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "hyperparams = {\n",
        "    'FT_TRANSFORMER': {}\n",
        "}\n",
        "\n",
        "predictor = TabularPredictor(label=label_column, problem_type='multiclass').fit(train_data, hyperparameters=hyperparams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpcm_5dSfqgQ",
        "outputId": "3d70e1ac-f0cd-42a5-fac5-41de0f5d95bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230811_121351/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230811_121351/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   144.79 GB / 179.07 GB (80.9%)\n",
            "Train Data Rows:    22740\n",
            "Train Data Columns: 16\n",
            "Label Column: interestingness\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6720.31 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2.91 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 12 | ['concreteness', 'valence', 'dominance', 'arousal', 'sentiment_vader', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 12 | ['concreteness', 'valence', 'dominance', 'arousal', 'sentiment_vader', ...]\n",
            "\t\t('int', [])   :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t0.2s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.91 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20466, Val Rows: 2274\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'FT_TRANSFORMER': {},\n",
            "}\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: FTTransformer ...\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type                        | Params\n",
            "------------------------------------------------------------------\n",
            "0 | model             | MultimodalFusionTransformer | 825 K \n",
            "1 | validation_metric | MulticlassAccuracy          | 0     \n",
            "2 | loss_func         | CrossEntropyLoss            | 0     \n",
            "------------------------------------------------------------------\n",
            "825 K     Trainable params\n",
            "0         Non-trainable params\n",
            "825 K     Total params\n",
            "1.651     Total estimated model params size (MB)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 80: 'val_accuracy' reached 0.75330 (best 0.75330), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=0-step=80.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 160: 'val_accuracy' reached 0.75901 (best 0.75901), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=0-step=160.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 240: 'val_accuracy' reached 0.75286 (best 0.75901), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=1-step=240.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 320: 'val_accuracy' reached 0.75770 (best 0.75901), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=1-step=320.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 400: 'val_accuracy' reached 0.76121 (best 0.76121), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=2-step=400.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 480: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 560: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 640: 'val_accuracy' reached 0.76737 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=3-step=640.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 720: 'val_accuracy' reached 0.76253 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=4-step=720.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 800: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 880: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 960: 'val_accuracy' reached 0.76209 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=5-step=960.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1040: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1120: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1200: 'val_accuracy' reached 0.76253 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=7-step=1200.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1280: 'val_accuracy' reached 0.76429 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=7-step=1280.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1360: 'val_accuracy' reached 0.76297 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=8-step=1360.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1440: 'val_accuracy' reached 0.76517 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=8-step=1440.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 1520: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 1600: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 10, global step 1680: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 10, global step 1760: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 11, global step 1840: 'val_accuracy' reached 0.76561 (best 0.76737), saving model to '/content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/epoch=11-step=1840.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 11, global step 1920: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 12, global step 2000: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 12, global step 2080: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 13, global step 2160: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 13, global step 2240: 'val_accuracy' was not in top 3\n",
            "\t0.7674\t = Validation score   (accuracy)\n",
            "\t90.09s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7674\t = Validation score   (accuracy)\n",
            "\t0.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 90.57s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230811_121351/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_test = test_data[label_column]\n",
        "test_data_nolab = test_data.drop(labels=[label_column], axis=1)\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "\n",
        "# Evaluate the performance\n",
        "performance = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, detailed_report='True')\n",
        "print(performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSGslzbygltN",
        "outputId": "a99098da-8d61-4ebe-deb5-806515379817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230811_121351/models/FTTransformer/automm_model/model.ckpt\n",
            "Evaluation: accuracy on test data: 0.7641160949868074\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.7641160949868074,\n",
            "    \"balanced_accuracy\": 0.48832780344279075,\n",
            "    \"mcc\": 0.3947979263308028\n",
            "}\n",
            "Detailed (per-class) classification report:\n",
            "{\n",
            "    \"0.0\": {\n",
            "        \"precision\": 0.6341463414634146,\n",
            "        \"recall\": 0.14730878186968838,\n",
            "        \"f1-score\": 0.2390804597701149,\n",
            "        \"support\": 353\n",
            "    },\n",
            "    \"1.0\": {\n",
            "        \"precision\": 0.7694798623760373,\n",
            "        \"recall\": 0.9555164614224679,\n",
            "        \"f1-score\": 0.8524663677130044,\n",
            "        \"support\": 3979\n",
            "    },\n",
            "    \"2.0\": {\n",
            "        \"precision\": 0.7401812688821753,\n",
            "        \"recall\": 0.36215816703621584,\n",
            "        \"f1-score\": 0.4863523573200993,\n",
            "        \"support\": 1353\n",
            "    },\n",
            "    \"accuracy\": 0.7641160949868074,\n",
            "    \"macro avg\": {\n",
            "        \"precision\": 0.7146024909072092,\n",
            "        \"recall\": 0.48832780344279075,\n",
            "        \"f1-score\": 0.5259663949344061,\n",
            "        \"support\": 5685\n",
            "    },\n",
            "    \"weighted avg\": {\n",
            "        \"precision\": 0.7541036565925103,\n",
            "        \"recall\": 0.7641160949868074,\n",
            "        \"f1-score\": 0.7272460543329797,\n",
            "        \"support\": 5685\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.7641160949868074, 'balanced_accuracy': 0.48832780344279075, 'mcc': 0.3947979263308028, 'confusion_matrix':      0.0   1.0  2.0\n",
            "0.0   52   280   21\n",
            "1.0   26  3802  151\n",
            "2.0    4   859  490, 'classification_report': {'0.0': {'precision': 0.6341463414634146, 'recall': 0.14730878186968838, 'f1-score': 0.2390804597701149, 'support': 353}, '1.0': {'precision': 0.7694798623760373, 'recall': 0.9555164614224679, 'f1-score': 0.8524663677130044, 'support': 3979}, '2.0': {'precision': 0.7401812688821753, 'recall': 0.36215816703621584, 'f1-score': 0.4863523573200993, 'support': 1353}, 'accuracy': 0.7641160949868074, 'macro avg': {'precision': 0.7146024909072092, 'recall': 0.48832780344279075, 'f1-score': 0.5259663949344061, 'support': 5685}, 'weighted avg': {'precision': 0.7541036565925103, 'recall': 0.7641160949868074, 'f1-score': 0.7272460543329797, 'support': 5685}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multimodal (Feature + Text)"
      ],
      "metadata": {
        "id": "XYo8JqgOgggO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in CSVs\n",
        "feature_df = pd.read_csv('/content/drive/My Drive/Data/feature_df.csv')\n",
        "print(len(feature_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goXSeOhZghsK",
        "outputId": "b8ca134d-95a0-4c12-c762-8599df018b4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter feature_df\n",
        "feature_df = feature_df[['preprocessed','interestingness', 'sentiment_BERT',\n",
        "                          'sentiment_RoBERTa', 'concreteness', 'valence', 'dominance', 'arousal',\n",
        "                          'sentiment_vader', 'readability', 'lexical_diversity', 'superlatives', 'novelty',\n",
        "                          'average_word_length', 'concreteness_lexical', 'valence_lexical',\n",
        "                          'dominance_lexical', 'arousal_lexical']]"
      ],
      "metadata": {
        "id": "uEXy8YNZkY9J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = feature_df.dropna()\n",
        "len(feature_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKNndJd_k6zq",
        "outputId": "d77c5e0b-65d4-4937-980f-1255e471a8a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28425"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data accordingly to Visual Studio splits (seed 42)\n",
        "\n",
        "label_column = 'interestingness'\n",
        "\n",
        "# Assuming feature_df is your dataframe\n",
        "X = feature_df.drop(columns=[label_column])\n",
        "y = feature_df[label_column]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, if you need the train and test data as TabularDataset:\n",
        "train_data = TabularDataset(pd.concat([X_train, y_train], axis=1))\n",
        "test_data = TabularDataset(pd.concat([X_test, y_test], axis=1))\n"
      ],
      "metadata": {
        "id": "YWALwDnqka0I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "predictor = TabularPredictor(label=label_column, problem_type='multiclass').fit(train_data, hyperparameters='multimodal')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d190a45d208429a92970246363052e7",
            "85fcbab795b54120a25daf6e1685fb9f",
            "3ebb070c088a422dbef02924c513d2f7",
            "39b0ab7c0d70486dbf221c25ac5252fb",
            "3f0897d9da88455da624a35dcbfad6ad",
            "e7db675ace1a434ea589eab66eaab57c",
            "21e4aa8d63a046469bdea1b4e0ab6efa",
            "561075b73fc24571a14c9098f88a06a7",
            "2035337872c74fbca8be4ab5d00be7e9",
            "20f6cdee08024119889cf2416115757c",
            "ed39ce37dd2e4ed6974fe0304c7434e5",
            "ab190718ccb04fc78957b76173a6d0f2",
            "ef03b473768e4c9c88e3dbf5f53cb4c9",
            "be89323e859f480d93fed13bcb20bbee",
            "3faa62924f5746ebb529e3797d5acc7b",
            "3b2716c53be84aab9d464b3a55d65b6a",
            "2b36d47f5f42417a88321303f6e49b5b",
            "a43d217ff49146e88e323a89e72ff921",
            "3d1574fd2b424f4cb1f0aabe8fecead6",
            "72d43a2e117d481ba45cb0809af08b29",
            "fcd74ef002be4183898fa0fb957ac3a8",
            "a66734a314984dbf9fd1cd100562b48d",
            "5a088f99d19d4b778c362fba71ee2792",
            "826363421cf948afbebaf3e92d1ef5e8",
            "d5333e3387ce418f85139e39c323ce7d",
            "ce5675fca097438386a001d7d2935722",
            "59fe610e2738442f805e87652963f8cc",
            "b167db6b112a4563982143be9281fb98",
            "f33c25978bdc4399979268feaf30056e",
            "ee9a41d272bb41a79c548cae712b3a9e",
            "64c4b7c823214919bfd3303e1b1f6cc4",
            "57897f43c25c45108c3590f2cc4480a2",
            "a98941799c704d47ad94f4b614a726ed",
            "3eadfd8fb22a421f87b974788f4c0a9d",
            "f2505f9f4f8a4b7da4efda2206adca6e",
            "4eeb90cd172c4537879b1061728559e0",
            "0655ba02ee2540a183aaeac7cb6f8d03",
            "431061fdce1544c8b7b0a704b261f9e8",
            "186e07a2e0974bd3bfb837c7b2f80549",
            "dedbb0e1e0c9447cbab3cb9138108df0",
            "97857558a3f54ec495f92ec4f85da021",
            "62ba1fe81d0d46e4bced07cf99d31c30",
            "ce1d746951a74102b8991f84b75d7920",
            "bc74391c9a414e45ac863bf731caa508",
            "7218115f00eb4d008cb7c778770e8fe5",
            "e11c0a711f664396ae28e3f5de046d4c",
            "237bfba15d63476684deaeb64572f748",
            "6bb366f99d634586bed3a7eba13108dd",
            "66841b67e3834755bbce2dcfdbd40c67",
            "8621d6fc87044620932e9bdb631c6ec8",
            "ebcb9994d6f04a2c9e83b937dfb37974",
            "8b364de122514d0db881a2cb3e3711d2",
            "a6b62229e6b74d9cb644febdedaf291f",
            "45de131671f74ab78a201feba748a61d",
            "bf86384c00bc4223bb7d0788d1889fe7"
          ]
        },
        "id": "OqG-oI_ekcR1",
        "outputId": "698ade51-28dc-41da-b0d8-561c98448fc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230815_062543/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230815_062543/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   144.61 GB / 179.07 GB (80.8%)\n",
            "Train Data Rows:    22740\n",
            "Train Data Columns: 17\n",
            "Label Column: interestingness\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11723.88 MB\n",
            "\tTrain Data (Original)  Memory Usage: 10.3 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tFitting RenameFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['preprocessed']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 4442\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 12 | ['concreteness', 'valence', 'dominance', 'arousal', 'sentiment_vader', ...]\n",
            "\t\t('int', [])          :  4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t\t('object', ['text']) :  1 | ['preprocessed']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', ['text_as_category'])  :    1 | ['preprocessed']\n",
            "\t\t('float', [])                       :   12 | ['concreteness', 'valence', 'dominance', 'arousal', 'sentiment_vader', ...]\n",
            "\t\t('int', [])                         :    4 | ['sentiment_BERT', 'sentiment_RoBERTa', 'superlatives', 'novelty']\n",
            "\t\t('int', ['binned', 'text_special']) :    6 | ['preprocessed.char_count', 'preprocessed.word_count', 'preprocessed.lower_ratio', 'preprocessed.digit_ratio', 'preprocessed.special_ratio', ...]\n",
            "\t\t('int', ['text_ngram'])             : 4146 | ['__nlp__.13th', '__nlp__.1st', '__nlp__.2020confusion', '__nlp__.2020confusion speakers', '__nlp__.2confusion', ...]\n",
            "\t\t('object', ['text'])                :    1 | ['preprocessed_raw_text']\n",
            "\t36.1s = Fit runtime\n",
            "\t17 features in original data used to generate 4170 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 199.09 MB (1.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 37.97s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 20466, Val Rows: 2274\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'AG_AUTOMM': {},\n",
            "\t'VW': {},\n",
            "}\n",
            "Fitting 8 L1 models ...\n",
            "Fitting model: LightGBM ...\n",
            "\t0.777\t = Validation score   (accuracy)\n",
            "\t24.36s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.7652\t = Validation score   (accuracy)\n",
            "\t35.69s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\tMany features detected (4169), dynamically setting 'colsample_bylevel' to 0.23986567522187574 to speed up training (Default = 1).\n",
            "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
            "\t0.7784\t = Validation score   (accuracy)\n",
            "\t75.79s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.7713\t = Validation score   (accuracy)\n",
            "\t115.01s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.7744\t = Validation score   (accuracy)\n",
            "\t23.01s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: VowpalWabbit ...\n",
            "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
            "\t\t`import vowpalwabbit` failed.\n",
            "A quick tip is to install via `pip install vowpalwabbit>=9,<9.5\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.7801\t = Validation score   (accuracy)\n",
            "\t60.92s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: MultiModalPredictor ...\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d190a45d208429a92970246363052e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab190718ccb04fc78957b76173a6d0f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a088f99d19d4b778c362fba71ee2792",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eadfd8fb22a421f87b974788f4c0a9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7218115f00eb4d008cb7c778770e8fe5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name              | Type                | Params\n",
            "----------------------------------------------------------\n",
            "0 | model             | MultimodalFusionMLP | 109 M \n",
            "1 | validation_metric | MulticlassAccuracy  | 0     \n",
            "2 | loss_func         | CrossEntropyLoss    | 0     \n",
            "----------------------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "219.573   Total estimated model params size (MB)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 79: 'val_accuracy' reached 0.73439 (best 0.73439), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=0-step=79.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 159: 'val_accuracy' reached 0.74978 (best 0.74978), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=0-step=159.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 239: 'val_accuracy' reached 0.76473 (best 0.76473), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=1-step=239.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 319: 'val_accuracy' reached 0.75814 (best 0.76473), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=1-step=319.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 399: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 479: 'val_accuracy' reached 0.76605 (best 0.76605), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=2-step=479.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 559: 'val_accuracy' reached 0.76957 (best 0.76957), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=3-step=559.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 639: 'val_accuracy' reached 0.77353 (best 0.77353), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=3-step=639.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 719: 'val_accuracy' reached 0.77573 (best 0.77573), saving model to '/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/epoch=4-step=719.ckpt' as top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 799: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 879: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 959: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1039: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1119: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1199: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 1279: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1359: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 1439: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 1519: 'val_accuracy' was not in top 3\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "Configuration saved in AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "tokenizer config file saved in AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/hf_text/tokenizer_config.json\n",
            "Special tokens file saved in AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/hf_text/special_tokens_map.json\n",
            "\t0.7753\t = Validation score   (accuracy)\n",
            "\t2337.35s\t = Training   runtime\n",
            "\t4.63s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7977\t = Validation score   (accuracy)\n",
            "\t0.54s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2722.07s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230815_062543/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test data\n",
        "y_test = test_data[label_column]\n",
        "test_data_nolab = test_data.drop(labels=[label_column], axis=1)\n",
        "y_pred = predictor.predict(test_data_nolab)\n",
        "\n",
        "# Evaluate the performance\n",
        "performance = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, detailed_report=\"True\")\n",
        "print(performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdPf50h0ks-5",
        "outputId": "c7723447-d56c-47b2-e69f-733e370c9213"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file /content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/hf_text/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"/content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/hf_text\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "Load pretrained checkpoint: /content/AutogluonModels/ag-20230815_062543/models/MultiModalPredictor/automm_model/model.ckpt\n",
            "Evaluation: accuracy on test data: 0.7883905013192612\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.7883905013192612,\n",
            "    \"balanced_accuracy\": 0.5656465751609074,\n",
            "    \"mcc\": 0.48603346219659904\n",
            "}\n",
            "Detailed (per-class) classification report:\n",
            "{\n",
            "    \"0.0\": {\n",
            "        \"precision\": 0.6915887850467289,\n",
            "        \"recall\": 0.2096317280453258,\n",
            "        \"f1-score\": 0.32173913043478264,\n",
            "        \"support\": 353\n",
            "    },\n",
            "    \"1.0\": {\n",
            "        \"precision\": 0.8157303370786517,\n",
            "        \"recall\": 0.9122895199798945,\n",
            "        \"f1-score\": 0.8613121366710168,\n",
            "        \"support\": 3979\n",
            "    },\n",
            "    \"2.0\": {\n",
            "        \"precision\": 0.6897163120567376,\n",
            "        \"recall\": 0.5750184774575019,\n",
            "        \"f1-score\": 0.6271664651350262,\n",
            "        \"support\": 1353\n",
            "    },\n",
            "    \"accuracy\": 0.7883905013192612,\n",
            "    \"macro avg\": {\n",
            "        \"precision\": 0.7323451447273728,\n",
            "        \"recall\": 0.5656465751609074,\n",
            "        \"f1-score\": 0.6034059107469419,\n",
            "        \"support\": 5685\n",
            "    },\n",
            "    \"weighted avg\": {\n",
            "        \"precision\": 0.7780313144362737,\n",
            "        \"recall\": 0.7883905013192612,\n",
            "        \"f1-score\": 0.7720828728557861,\n",
            "        \"support\": 5685\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.7883905013192612, 'balanced_accuracy': 0.5656465751609074, 'mcc': 0.48603346219659904, 'confusion_matrix':      0.0   1.0  2.0\n",
            "0.0   74   247   32\n",
            "1.0   31  3630  318\n",
            "2.0    2   573  778, 'classification_report': {'0.0': {'precision': 0.6915887850467289, 'recall': 0.2096317280453258, 'f1-score': 0.32173913043478264, 'support': 353}, '1.0': {'precision': 0.8157303370786517, 'recall': 0.9122895199798945, 'f1-score': 0.8613121366710168, 'support': 3979}, '2.0': {'precision': 0.6897163120567376, 'recall': 0.5750184774575019, 'f1-score': 0.6271664651350262, 'support': 1353}, 'accuracy': 0.7883905013192612, 'macro avg': {'precision': 0.7323451447273728, 'recall': 0.5656465751609074, 'f1-score': 0.6034059107469419, 'support': 5685}, 'weighted avg': {'precision': 0.7780313144362737, 'recall': 0.7883905013192612, 'f1-score': 0.7720828728557861, 'support': 5685}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data)\n"
      ],
      "metadata": {
        "id": "fOYVKgKlkwwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}